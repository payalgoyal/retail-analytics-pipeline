[2025-06-15T03:22:50.446+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:22:50.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:22:50.448+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:22:50.448+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:22:51.813+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:22:51.961+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:22:51.960+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:22:51.980+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:22:51.979+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-14 00:00:00+00:00, run_after=2025-06-15 00:00:00+00:00
[2025-06-15T03:22:52.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.566 seconds
[2025-06-15T03:23:22.911+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:22.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:23:22.914+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:22.913+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:23.275+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:23.276+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:23.276+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:23.300+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:23.300+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:23:23.328+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:23.328+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:23:23.343+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:23.343+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:23:23.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.458 seconds
[2025-06-15T03:23:54.405+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:54.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:23:54.409+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:54.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:54.788+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:54.789+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:54.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:23:54.807+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:54.807+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:23:54.830+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:54.830+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:23:54.842+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:23:54.842+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:23:54.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.459 seconds
[2025-06-15T03:24:25.888+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:25.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:24:25.890+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:25.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:26.297+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:26.299+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:26.298+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:26.337+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:26.336+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:24:26.367+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:26.367+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:24:26.383+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:26.382+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:24:26.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.521 seconds
[2025-06-15T03:24:57.116+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:57.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:24:57.118+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:57.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:57.509+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:57.510+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:57.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:24:57.538+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:57.538+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:24:57.566+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:57.566+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:24:57.581+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:24:57.581+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:24:57.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.494 seconds
[2025-06-15T03:25:20.630+0000] {processor.py:161} INFO - Started process (PID=241) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:20.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:25:20.634+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:20.634+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:21.086+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:21.087+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:21.086+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:21.106+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:21.106+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:25:21.192+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:21.192+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:25:21.207+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:21.206+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:25:21.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.606 seconds
[2025-06-15T03:25:47.099+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:47.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:25:47.102+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:47.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:48.031+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:25:48.183+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:48.182+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:25:48.201+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:25:48.200+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:25:48.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.127 seconds
[2025-06-15T03:26:18.475+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:18.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:26:18.477+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:18.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:18.827+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:18.828+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:18.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:18.844+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:18.844+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:26:18.869+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:18.869+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:26:18.883+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:18.883+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:26:18.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.430 seconds
[2025-06-15T03:26:48.953+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:48.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:26:48.956+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:48.955+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:49.356+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:49.357+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:49.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:26:49.375+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:49.375+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:26:49.403+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:49.403+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:26:49.417+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:26:49.417+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:26:49.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.486 seconds
[2025-06-15T03:27:18.448+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:18.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:27:18.450+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:18.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:18.860+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:18.861+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:18.861+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:18.883+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:18.883+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:27:18.964+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:18.964+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:27:18.976+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:18.976+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:27:19.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.555 seconds
[2025-06-15T03:27:49.711+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:49.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:27:49.713+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:49.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:50.161+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:50.162+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:50.162+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:27:50.188+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:50.188+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:27:50.220+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:50.220+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:27:50.239+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:27:50.239+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:27:50.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.556 seconds
[2025-06-15T03:29:05.691+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:05.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:29:05.693+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:05.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:06.740+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:06.968+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:06.967+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:29:06.993+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:06.993+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:29:07.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.349 seconds
[2025-06-15T03:29:37.986+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:37.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:29:37.989+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:37.988+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:38.416+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:38.420+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:38.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:29:38.446+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:38.446+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:29:38.475+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:38.474+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:29:38.489+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:29:38.489+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:29:38.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.545 seconds
[2025-06-15T03:30:09.429+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:09.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:30:09.431+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:09.431+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:09.875+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:09.876+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:09.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:09.902+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:09.901+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:30:09.930+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:09.930+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:30:09.943+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:09.943+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:30:09.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.538 seconds
[2025-06-15T03:30:40.642+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:40.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:30:40.644+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:40.643+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:41.046+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:41.047+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:41.046+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:30:41.083+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:41.082+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T03:30:41.110+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:41.109+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:30:41.123+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:30:41.123+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:30:41.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.501 seconds
[2025-06-15T03:31:11.381+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:31:11.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:31:11.383+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:31:11.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:31:11.759+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:31:11.777+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:31:11.777+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:31:11.793+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:31:11.792+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:31:11.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.434 seconds
[2025-06-15T03:31:42.068+0000] {processor.py:161} INFO - Started process (PID=241) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:31:42.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:31:42.070+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:31:42.069+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:31:42.469+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:31:42.485+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:31:42.485+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:31:42.503+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:31:42.502+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:31:42.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.467 seconds
[2025-06-15T03:32:12.791+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:32:12.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:32:12.793+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:32:12.793+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:32:13.150+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:32:13.166+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:32:13.166+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:32:13.180+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:32:13.180+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:32:13.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.416 seconds
[2025-06-15T03:32:43.458+0000] {processor.py:161} INFO - Started process (PID=253) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:32:43.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T03:32:43.460+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:32:43.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:32:43.855+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T03:32:43.871+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:32:43.871+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T03:32:43.889+0000] {logging_mixin.py:188} INFO - [2025-06-15T03:32:43.889+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T03:32:43.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.454 seconds
[2025-06-15T05:39:08.042+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:39:08.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:39:08.046+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:39:08.046+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:39:09.010+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:39:09.003+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 12, in <module>
    from data_extract import extract_data
ModuleNotFoundError: No module named 'data_extract'
[2025-06-15T05:39:09.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:39:09.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.016 seconds
[2025-06-15T05:39:39.253+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:39:39.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:39:39.255+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:39:39.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:39:39.460+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:39:39.454+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 12, in <module>
    from data_extract import extract_data
ModuleNotFoundError: No module named 'data_extract'
[2025-06-15T05:39:39.461+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:39:39.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.231 seconds
[2025-06-15T05:40:09.724+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:40:09.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:40:09.726+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:40:09.726+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:40:09.939+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:40:09.933+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 12, in <module>
    from data_extract import extract_data
ModuleNotFoundError: No module named 'data_extract'
[2025-06-15T05:40:09.941+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:40:09.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.243 seconds
[2025-06-15T05:40:40.186+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:40:40.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:40:40.188+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:40:40.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:40:40.400+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:40:40.393+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 12, in <module>
    from data_extract import extract_data
ModuleNotFoundError: No module named 'data_extract'
[2025-06-15T05:40:40.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:40:40.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.238 seconds
[2025-06-15T05:41:36.944+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:41:36.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:41:36.946+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:41:36.946+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:41:38.037+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:41:38.027+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:41:38.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:41:38.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.141 seconds
[2025-06-15T05:42:08.186+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:42:08.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:42:08.188+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:42:08.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:42:08.465+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:42:08.460+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:42:08.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:42:08.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.308 seconds
[2025-06-15T05:42:38.758+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:42:38.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:42:38.761+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:42:38.761+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:42:39.104+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:42:39.095+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:42:39.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:42:39.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.381 seconds
[2025-06-15T05:43:16.714+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:43:16.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:43:16.717+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:43:16.716+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:43:17.764+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:43:17.748+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:43:17.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:43:17.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.099 seconds
[2025-06-15T05:43:48.002+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:43:48.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:43:48.004+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:43:48.004+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:43:48.265+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:43:48.260+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:43:48.266+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:43:48.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.305 seconds
[2025-06-15T05:44:18.689+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:44:18.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:44:18.692+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:44:18.692+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:44:19.043+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:44:19.035+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:44:19.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:44:19.071+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.385 seconds
[2025-06-15T05:45:01.465+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:45:01.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:45:01.467+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:45:01.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:45:02.248+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:45:02.240+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:45:02.249+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:45:02.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.814 seconds
[2025-06-15T05:45:32.551+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:45:32.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:45:32.554+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:45:32.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:45:32.894+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:45:32.885+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:45:32.895+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:45:32.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.378 seconds
[2025-06-15T05:46:03.168+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:46:03.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:46:03.170+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:46:03.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:46:03.415+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:46:03.411+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:46:03.416+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:46:03.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.270 seconds
[2025-06-15T05:46:46.755+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:46:46.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:46:46.758+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:46:46.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:46:47.898+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:46:47.887+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:46:47.900+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:46:47.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.186 seconds
[2025-06-15T05:47:18.003+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:47:18.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:47:18.006+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:47:18.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:47:18.343+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:47:18.335+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:47:18.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:47:18.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.375 seconds
[2025-06-15T05:47:48.708+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:47:48.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:47:48.711+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:47:48.710+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:47:48.997+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:47:48.991+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:47:48.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:47:49.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.313 seconds
[2025-06-15T05:50:28.331+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:50:28.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:50:28.334+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:50:28.334+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:50:29.153+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:50:29.144+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:50:29.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:50:29.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.854 seconds
[2025-06-15T05:50:59.471+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:50:59.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:50:59.473+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:50:59.473+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:50:59.779+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:50:59.774+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:50:59.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:50:59.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.338 seconds
[2025-06-15T05:51:30.044+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:51:30.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:51:30.046+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:51:30.046+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:51:30.318+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:51:30.313+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:51:30.319+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:51:30.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.301 seconds
[2025-06-15T05:52:00.593+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:52:00.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:52:00.595+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:52:00.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:52:00.923+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:52:00.911+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:52:00.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:52:01.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.433 seconds
[2025-06-15T05:52:39.409+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:52:39.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:52:39.411+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:52:39.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:52:40.578+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:52:40.564+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:52:40.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:52:40.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.224 seconds
[2025-06-15T05:53:10.870+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:53:10.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:53:10.873+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:53:10.872+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:53:11.121+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:53:11.118+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:53:11.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:53:11.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.276 seconds
[2025-06-15T05:53:41.447+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:53:41.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T05:53:41.449+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:53:41.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:53:41.772+0000] {logging_mixin.py:188} INFO - [2025-06-15T05:53:41.761+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T05:53:41.773+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T05:53:41.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.359 seconds
[2025-06-15T06:52:41.353+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:52:41.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:52:41.357+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:52:41.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:52:42.336+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:52:42.328+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T06:52:42.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:52:42.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.014 seconds
[2025-06-15T06:53:12.666+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:53:12.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:53:12.668+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:53:12.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:53:13.214+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:53:13.200+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T06:53:13.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:53:13.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.594 seconds
[2025-06-15T06:53:43.673+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:53:43.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:53:43.684+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:53:43.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:53:44.501+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:53:44.487+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 16, in <module>
    from data_load_to_sql import load_to_sql
  File "/opt/airflow/utils/data_load_to_sql.py", line 21, in <module>
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:3306/{database}')
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2025-06-15T06:53:44.502+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:53:44.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.875 seconds
[2025-06-15T06:54:14.929+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:54:14.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:57:39.555+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:57:39.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:57:39.558+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:39.558+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:57:40.725+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:57:40.982+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:40.981+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:retail_analytics_airflowDAG
[2025-06-15T06:57:40.995+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:40.995+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:retail_analytics_airflowDAG
[2025-06-15T06:57:41.007+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:41.006+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:retail_analytics_airflowDAG
[2025-06-15T06:57:41.008+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:41.007+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T06:57:41.021+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:41.021+0000] {dag.py:3058} INFO - Creating ORM DAG for retail_analytics_airflowDAG
[2025-06-15T06:57:41.034+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:57:41.034+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-14 00:00:00+00:00, run_after=2025-06-15 00:00:00+00:00
[2025-06-15T06:57:41.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.510 seconds
[2025-06-15T06:58:11.332+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:58:11.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:58:11.335+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:58:11.335+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:58:11.766+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:58:11.782+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:58:11.782+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T06:58:11.810+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:58:11.810+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-14 00:00:00+00:00, run_after=2025-06-15 00:00:00+00:00
[2025-06-15T06:58:11.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.515 seconds
[2025-06-15T06:58:42.141+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:58:42.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:58:42.144+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:58:42.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:58:42.540+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:58:42.681+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:58:42.680+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T06:58:42.707+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:58:42.707+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-14 00:00:00+00:00, run_after=2025-06-15 00:00:00+00:00
[2025-06-15T06:58:42.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.611 seconds
[2025-06-15T06:59:13.007+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:13.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:59:13.011+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:13.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:13.512+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:13.513+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:13.513+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:13.579+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:13.579+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T06:59:13.631+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:13.631+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T06:59:13.655+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:13.654+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T06:59:13.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.678 seconds
[2025-06-15T06:59:44.639+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:44.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T06:59:44.643+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:44.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:45.327+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:45.330+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:45.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T06:59:45.378+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:45.378+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T06:59:45.457+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:45.457+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T06:59:45.487+0000] {logging_mixin.py:188} INFO - [2025-06-15T06:59:45.486+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T06:59:45.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.889 seconds
[2025-06-15T07:00:16.525+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:16.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:00:16.528+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:16.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:16.955+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:16.956+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:16.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:16.985+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:16.985+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:00:17.029+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:17.029+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:00:17.047+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:17.047+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:00:17.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.560 seconds
[2025-06-15T07:00:47.213+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:47.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:00:47.216+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:47.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:47.880+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:47.884+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:47.883+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:00:47.979+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:47.978+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:00:48.067+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:48.067+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:00:48.095+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:00:48.094+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:00:48.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.935 seconds
[2025-06-15T07:01:18.692+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:18.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:01:18.696+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:18.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:19.055+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:19.056+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:19.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:19.087+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:19.087+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:01:19.142+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:19.142+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:01:19.164+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:19.164+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:01:19.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.515 seconds
[2025-06-15T07:01:49.504+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:49.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:01:49.508+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:49.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:49.989+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:49.991+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:49.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:01:50.034+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:50.034+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:01:50.102+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:50.102+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:01:50.127+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:01:50.126+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:01:50.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.668 seconds
[2025-06-15T07:02:21.235+0000] {processor.py:161} INFO - Started process (PID=250) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:21.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:02:21.238+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:21.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:21.689+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:21.691+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:21.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:21.747+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:21.747+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:02:21.802+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:21.802+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:02:21.834+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:21.833+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:02:21.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.666 seconds
[2025-06-15T07:02:51.979+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:51.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:02:51.983+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:51.983+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:52.425+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:52.427+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:52.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:02:52.478+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:52.478+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:02:52.539+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:52.539+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:02:52.564+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:02:52.563+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:02:52.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.638 seconds
[2025-06-15T07:03:42.256+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:03:42.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:03:42.259+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:03:42.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:03:42.804+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:03:42.851+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:03:42.851+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:03:42.896+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:03:42.896+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:03:42.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.685 seconds
[2025-06-15T07:04:13.226+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:13.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:04:13.228+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:13.228+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:13.735+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:13.736+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:13.736+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:13.785+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:13.785+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:04:13.820+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:13.820+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:04:13.835+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:13.834+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:04:13.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.644 seconds
[2025-06-15T07:04:44.144+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:44.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:04:44.154+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:44.154+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:44.729+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:04:44.866+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:44.865+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:04:44.896+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:04:44.895+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:04:44.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.809 seconds
[2025-06-15T07:05:15.439+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:15.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:05:15.441+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:15.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:15.989+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:15.990+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:15.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:16.012+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:16.012+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:05:16.050+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:16.050+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:05:16.066+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:16.065+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:05:16.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.662 seconds
[2025-06-15T07:05:47.072+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:47.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:05:47.075+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:47.074+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:47.765+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:47.767+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:47.766+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:05:47.817+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:47.817+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:05:47.879+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:47.878+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:05:47.906+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:05:47.905+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:05:47.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.884 seconds
[2025-06-15T07:06:18.795+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:18.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:06:18.802+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:18.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:20.218+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:20.219+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:20.219+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:20.250+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:20.250+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:06:20.292+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:20.292+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:06:20.313+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:20.313+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:06:20.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.572 seconds
[2025-06-15T07:06:50.615+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:50.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:06:50.622+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:50.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:51.803+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:51.805+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:51.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:06:51.849+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:51.849+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:06:51.895+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:51.894+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:06:51.918+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:06:51.917+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:06:51.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.350 seconds
[2025-06-15T07:07:22.917+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:22.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:07:22.920+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:22.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:23.525+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:23.527+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:23.526+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:23.565+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:23.565+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:07:23.610+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:23.610+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:07:23.642+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:23.642+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:07:23.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.763 seconds
[2025-06-15T07:07:53.926+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:53.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:07:53.929+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:53.928+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:55.193+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:55.194+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:55.194+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:07:55.237+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:55.236+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:07:55.288+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:55.287+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:07:55.311+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:07:55.310+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:07:55.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.424 seconds
[2025-06-15T07:08:36.787+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:08:36.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:08:36.791+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:08:36.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:08:37.817+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:08:37.886+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:08:37.885+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:08:37.919+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:08:37.919+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:08:37.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.178 seconds
[2025-06-15T07:09:08.042+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:08.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:09:08.045+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:08.525+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:08.526+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:08.554+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.554+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:09:08.580+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.579+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:08.594+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.594+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:09:08.606+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.606+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:09:08.626+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:08.626+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:09:08.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.614 seconds
[2025-06-15T07:09:39.374+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:39.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:09:39.377+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:39.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:39.886+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:39.887+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:39.886+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:09:39.918+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:39.917+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T07:09:40.029+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:40.028+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:09:40.045+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:09:40.044+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:09:40.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.706 seconds
[2025-06-15T07:10:10.479+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:10:10.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:10:10.482+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:10:10.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:10:11.073+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:10:11.100+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:10:11.099+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:10:11.127+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:10:11.127+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:10:11.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.681 seconds
[2025-06-15T07:10:41.466+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:10:41.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:10:41.468+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:10:41.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:10:42.019+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:10:42.049+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:10:42.049+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:10:42.078+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:10:42.078+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:10:42.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.650 seconds
[2025-06-15T07:11:12.262+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:11:12.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:11:12.265+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:11:12.265+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:11:12.845+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:11:12.878+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:11:12.878+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:11:12.901+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:11:12.901+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:11:12.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.677 seconds
[2025-06-15T07:11:43.283+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:11:43.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:11:43.289+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:11:43.288+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:11:44.000+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:11:44.026+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:11:44.026+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:11:44.050+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:11:44.050+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:11:44.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.817 seconds
[2025-06-15T07:12:14.416+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:12:14.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T07:12:14.420+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:12:14.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:12:14.899+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T07:12:14.925+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:12:14.925+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T07:12:14.945+0000] {logging_mixin.py:188} INFO - [2025-06-15T07:12:14.944+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T07:12:14.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.563 seconds
[2025-06-15T10:13:04.584+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:13:04.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:13:04.589+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:13:04.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:13:06.423+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:13:06.422+0000] {font_manager.py:1547} INFO - generated new fontManager
[2025-06-15T10:13:34.616+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:13:34.615+0000] {timeout.py:68} ERROR - Process timed out, PID: 166
[2025-06-15T10:13:34.621+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:13:34.617+0000] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1330, in _read_rowdata_packet
    packet = self.connection._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 744, in _read_packet
    packet_header = self._read_bytes(4)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_bytes
    self._sock.settimeout(self._read_timeout)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 166

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 49 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 49 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 492, in rollback
    self._execute_command(COMMAND.COM_QUERY, "ROLLBACK")
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 843, in _execute_command
    raise err.InterfaceError(0, "")
pymysql.err.InterfaceError: (0, '')
[2025-06-15T10:13:34.645+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:13:34.622+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1330, in _read_rowdata_packet
    packet = self.connection._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 744, in _read_packet
    packet_header = self._read_bytes(4)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_bytes
    self._sock.settimeout(self._read_timeout)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 166

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 49 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 49 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2025-06-15T10:13:34.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:13:35.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.438 seconds
[2025-06-15T10:14:05.152+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:14:05.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:14:05.156+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:14:05.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:14:35.176+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:14:35.174+0000] {timeout.py:68} ERROR - Process timed out, PID: 175
[2025-06-15T10:14:35.200+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:14:35.178+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 170, in read_length_coded_string
    length = self.read_length_encoded_integer()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 151, in read_length_encoded_integer
    c = self.read_uint8()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 114, in read_uint8
    self._position += 1
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 175

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 753, in _read_packet
    raise err.OperationalError(
pymysql.err.OperationalError: (2013, 'Lost connection to MySQL server during query')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 753, in _read_packet
    raise err.OperationalError(
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2013, 'Lost connection to MySQL server during query')
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-06-15T10:14:35.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:14:35.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.365 seconds
[2025-06-15T10:15:05.937+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:15:05.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:15:05.947+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:15:05.946+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:15:54.999+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:15:55.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:15:55.002+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:15:55.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:15:56.577+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:15:56.845+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:15:56.844+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:15:56.875+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:15:56.874+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:15:56.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.922 seconds
[2025-06-15T10:16:27.323+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:16:27.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:16:27.326+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:16:27.326+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:16:27.720+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:16:27.732+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:16:27.732+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:16:27.756+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:16:27.756+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:16:27.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.493 seconds
[2025-06-15T10:17:39.104+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:17:39.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:17:39.108+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:17:39.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:17:41.049+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:17:41.049+0000] {font_manager.py:1547} INFO - generated new fontManager
[2025-06-15T10:18:09.125+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:18:09.123+0000] {timeout.py:68} ERROR - Process timed out, PID: 166
[2025-06-15T10:18:09.131+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:18:09.127+0000] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 173, in read_length_coded_string
    return self.read(length)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 65, in read
    if len(result) != size:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 166

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 177 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 177 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 492, in rollback
    self._execute_command(COMMAND.COM_QUERY, "ROLLBACK")
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 843, in _execute_command
    raise err.InterfaceError(0, "")
pymysql.err.InterfaceError: (0, '')
[2025-06-15T10:18:09.152+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:18:09.132+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 173, in read_length_coded_string
    return self.read(length)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 65, in read
    if len(result) != size:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 166

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 177 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 177 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2025-06-15T10:18:09.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:18:09.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.289 seconds
[2025-06-15T10:18:39.738+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:18:39.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:18:39.744+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:18:39.743+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:19:09.773+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:19:09.773+0000] {timeout.py:68} ERROR - Process timed out, PID: 175
[2025-06-15T10:19:09.777+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:19:09.774+0000] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 170, in read_length_coded_string
    length = self.read_length_encoded_integer()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 175

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 66 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 66 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 492, in rollback
    self._execute_command(COMMAND.COM_QUERY, "ROLLBACK")
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 843, in _execute_command
    raise err.InterfaceError(0, "")
pymysql.err.InterfaceError: (0, '')
[2025-06-15T10:19:09.785+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:19:09.778+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 170, in read_length_coded_string
    length = self.read_length_encoded_integer()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 175

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 66 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 66 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2025-06-15T10:19:09.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:19:09.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.256 seconds
[2025-06-15T10:19:40.191+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:19:40.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:19:40.195+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:19:40.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:20:10.207+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:20:10.205+0000] {timeout.py:68} ERROR - Process timed out, PID: 181
[2025-06-15T10:20:10.213+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:20:10.209+0000] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1350, in _read_row_from_packet
    data = data.decode(encoding)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 181

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 146 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 146 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 492, in rollback
    self._execute_command(COMMAND.COM_QUERY, "ROLLBACK")
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 843, in _execute_command
    raise err.InterfaceError(0, "")
pymysql.err.InterfaceError: (0, '')
[2025-06-15T10:20:10.220+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:20:10.214+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1350, in _read_row_from_packet
    data = data.decode(encoding)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 181

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 146 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 146 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2025-06-15T10:20:10.221+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:20:10.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.416 seconds
[2025-06-15T10:20:40.678+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:20:40.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:20:40.680+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:20:40.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:21:10.693+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:21:10.691+0000] {timeout.py:68} ERROR - Process timed out, PID: 187
[2025-06-15T10:21:10.700+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:21:10.695+0000] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1330, in _read_rowdata_packet
    packet = self.connection._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 744, in _read_packet
    packet_header = self._read_bytes(4)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_bytes
    self._sock.settimeout(self._read_timeout)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 187

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 69 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 69 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 492, in rollback
    self._execute_command(COMMAND.COM_QUERY, "ROLLBACK")
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 843, in _execute_command
    raise err.InterfaceError(0, "")
pymysql.err.InterfaceError: (0, '')
[2025-06-15T10:21:10.710+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:21:10.701+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1330, in _read_rowdata_packet
    packet = self.connection._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 744, in _read_packet
    packet_header = self._read_bytes(4)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_bytes
    self._sock.settimeout(self._read_timeout)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 187

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 69 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 69 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2025-06-15T10:21:10.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:21:10.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.078 seconds
[2025-06-15T10:21:41.090+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:21:41.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:21:41.092+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:21:41.092+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:22:11.103+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:22:11.102+0000] {timeout.py:68} ERROR - Process timed out, PID: 193
[2025-06-15T10:22:11.107+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:22:11.104+0000] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 173, in read_length_coded_string
    return self.read(length)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 64, in read
    result = self._data[self._position : (self._position + size)]
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 193

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 36 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 36 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 492, in rollback
    self._execute_command(COMMAND.COM_QUERY, "ROLLBACK")
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 843, in _execute_command
    raise err.InterfaceError(0, "")
pymysql.err.InterfaceError: (0, '')
[2025-06-15T10:22:11.121+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:22:11.108+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 153, in execute
    result = self._query(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/cursors.py", line 322, in _query
    conn.query(q)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 825, in _read_query_result
    result.read()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1206, in read
    self._read_result_packet(first_packet)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1283, in _read_result_packet
    self._read_rowdata_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1334, in _read_rowdata_packet
    rows.append(self._read_row_from_packet(packet))
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 1343, in _read_row_from_packet
    data = packet.read_length_coded_string()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 173, in read_length_coded_string
    return self.read(length)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/protocol.py", line 64, in read
    result = self._data[self._position : (self._position + size)]
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.8.1/best-practices.html#reducing-dag-complexity, PID: 193

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
pymysql.err.InternalError: Packet sequence number wrong - got 36 expected 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_dag.py", line 17, in <module>
    from data_analysis import analysis
  File "/opt/airflow/utils/data_analysis.py", line 47, in <module>
    df = pd.read_sql("SELECT * FROM sales_gold", engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 663, in read_sql
    return pandas_sql.read_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1738, in read_query
    result = self.execute(sql, params)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1562, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1770, in exec_driver_sql
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 84, in __exit__
    compat.raise_(value, with_traceback=traceback)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    self._autorollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1192, in _autorollback
    self._rollback_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1064, in _rollback_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2036, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1062, in _rollback_impl
    self.engine.dialect.do_rollback(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 493, in rollback
    self._read_ok_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 453, in _read_ok_packet
    pkt = self._read_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 757, in _read_packet
    raise err.InternalError(
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) Packet sequence number wrong - got 36 expected 1
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2025-06-15T10:22:11.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:22:11.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 30.326 seconds
[2025-06-15T10:22:41.770+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:22:41.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:22:41.772+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:22:41.772+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:23.784+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:23.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:25:23.787+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:23.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:25.173+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:25.173+0000] {font_manager.py:1547} INFO - generated new fontManager
[2025-06-15T10:25:25.446+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:25.625+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:25.625+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:25:25.648+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:25.648+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:25:25.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.906 seconds
[2025-06-15T10:25:55.922+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:55.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:25:55.926+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:55.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:56.635+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:25:56.644+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:56.644+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:25:56.662+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:25:56.662+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:25:56.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.763 seconds
[2025-06-15T10:26:27.375+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:27.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:26:27.377+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:27.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:28.119+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:28.120+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:28.119+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:28.142+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:28.142+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:26:28.229+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:28.229+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:26:28.244+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:28.243+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:26:28.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.894 seconds
[2025-06-15T10:26:58.855+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:58.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:26:58.857+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:58.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:59.577+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:59.578+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:59.577+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:26:59.609+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:59.609+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:26:59.648+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:59.648+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:26:59.663+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:26:59.663+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:26:59.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.836 seconds
[2025-06-15T10:27:30.141+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:27:30.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:27:30.190+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:27:30.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:27:30.850+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:27:30.851+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:27:30.850+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:27:30.870+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:27:30.870+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:27:30.901+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:27:30.900+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:27:30.916+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:27:30.916+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:27:30.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.803 seconds
[2025-06-15T10:28:01.468+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:01.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:28:01.472+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:01.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:02.197+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:02.198+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:02.198+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:02.229+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:02.229+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:28:02.260+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:02.260+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:28:02.274+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:02.274+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:28:02.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.833 seconds
[2025-06-15T10:28:32.843+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:32.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:28:32.847+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:32.846+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:34.182+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:34.184+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:34.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:28:34.221+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:34.221+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:28:34.269+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:34.268+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:28:34.292+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:28:34.292+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:28:34.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.488 seconds
[2025-06-15T10:30:15.473+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:15.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:30:15.476+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:15.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:16.926+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:16.926+0000] {font_manager.py:1547} INFO - generated new fontManager
[2025-06-15T10:30:17.147+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:17.183+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:17.183+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:30:17.202+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:17.202+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:30:17.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.756 seconds
[2025-06-15T10:30:47.822+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:47.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:30:47.825+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:47.824+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:48.627+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:48.628+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:48.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:48.652+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:48.651+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:30:48.670+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:48.670+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:30:48.684+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:48.684+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:30:48.693+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:48.693+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:30:48.711+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:30:48.711+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:30:48.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.915 seconds
[2025-06-15T10:31:19.179+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:19.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:31:19.183+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:19.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:19.865+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:19.866+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:19.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:19.886+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:19.886+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:31:19.903+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:19.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:19.917+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:19.917+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:31:20.046+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:20.045+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:31:20.059+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:20.059+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:31:20.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.905 seconds
[2025-06-15T10:31:50.299+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:50.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:31:50.301+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:50.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:50.963+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:31:50.982+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:50.981+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:31:50.999+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:31:50.999+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:31:51.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.729 seconds
[2025-06-15T10:32:21.238+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:32:21.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:32:21.240+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:32:21.240+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:32:21.932+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:32:21.965+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:32:21.965+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:32:21.986+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:32:21.986+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:32:22.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.775 seconds
[2025-06-15T10:32:52.226+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:32:52.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:32:52.228+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:32:52.228+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:32:52.871+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:32:52.892+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:32:52.892+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:32:52.911+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:32:52.911+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:32:52.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.706 seconds
[2025-06-15T10:33:23.351+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:23.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:33:23.355+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:23.354+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:24.034+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:24.036+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:24.035+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:24.070+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:24.070+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:33:24.098+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:24.098+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:33:24.111+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:24.111+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:33:24.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.786 seconds
[2025-06-15T10:33:54.680+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:54.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:33:54.682+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:54.682+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:55.389+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:55.390+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:55.389+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:33:55.414+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:55.413+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:33:55.442+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:55.441+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:33:55.460+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:33:55.460+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:33:55.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.815 seconds
[2025-06-15T10:34:26.178+0000] {processor.py:161} INFO - Started process (PID=253) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:26.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:34:26.180+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:26.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:26.952+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:26.953+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:26.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:26.981+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:26.981+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:34:27.015+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:27.015+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:34:27.032+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:27.031+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:34:27.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.893 seconds
[2025-06-15T10:34:57.633+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:57.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-06-15T10:34:57.637+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:57.636+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:58.788+0000] {processor.py:840} INFO - DAG(s) 'retail_analytics_airflowDAG' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:58.789+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:58.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-06-15T10:34:58.822+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:58.821+0000] {processor.py:431} INFO - Running SLA Checks for retail_analytics_airflowDAG
[2025-06-15T10:34:58.875+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:58.874+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-06-15T10:34:58.898+0000] {logging_mixin.py:188} INFO - [2025-06-15T10:34:58.897+0000] {dag.py:3823} INFO - Setting next_dagrun for retail_analytics_airflowDAG to 2025-06-15 00:00:00+00:00, run_after=2025-06-16 00:00:00+00:00
[2025-06-15T10:34:58.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 1.297 seconds
